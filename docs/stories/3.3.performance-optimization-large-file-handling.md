# Story 3.3: Performance Optimization & Large File Handling

## Status

Approved

## Story

**As a** user,
**I want** the application to handle large directories efficiently,
**so that** I can process thousands of files without performance degradation.

## Acceptance Criteria

1. File list populates progressively for directories với 1000+ files
2. Preview generation optimized to handle large file counts quickly
3. Memory usage remains stable during large batch operations
4. Background processing doesn't block UI interactions
5. File system monitoring detects external changes to selected directory
6. Application startup time remains under 2 seconds regardless of last used folder size
7. Batch operations provide estimated completion times for large operations
8. System resource usage optimized for sustained operation

## Tasks / Subtasks

- [ ] Implement progressive file loading system (AC: 1, 6)
  - [ ] Create FileStreamingService với chunked directory scanning
  - [ ] Implement pagination for UI file list display
  - [ ] Add progressive loading indicators với current file count
  - [ ] Optimize SQLite queries với LIMIT và OFFSET clauses
- [ ] Optimize preview generation performance (AC: 2, 7)
  - [ ] Implement parallel processing cho normalization operations
  - [ ] Add preview result caching với file modification time checking
  - [ ] Create performance profiler để identify bottlenecks
  - [ ] Implement estimated completion time calculation algorithm
- [ ] Optimize memory management for large operations (AC: 3, 8)
  - [ ] Implement memory-efficient data structures với generators
  - [ ] Add periodic garbage collection triggers
  - [ ] Create memory usage monitoring với threshold alerts
  - [ ] Implement file batch processing với configurable chunk sizes
- [ ] Implement asynchronous processing architecture (AC: 4, 5)
  - [ ] Refactor UI components to use async/await patterns
  - [ ] Create background task queue với priority scheduling
  - [ ] Implement file system watcher với debounced change notifications
  - [ ] Add cancellation token support cho long-running operations
- [ ] Create performance monitoring và resource optimization (AC: 8)
  - [ ] Implement system resource monitor với CPU và RAM tracking
  - [ ] Add adaptive performance scaling based on system capabilities
  - [ ] Create performance metrics collection và reporting
  - [ ] Implement thread pool optimization cho I/O operations
- [ ] Implement comprehensive performance testing (All ACs)
  - [ ] Unit tests cho streaming file service với large datasets
  - [ ] Performance benchmarks cho 1000, 10000, và 50000+ file directories
  - [ ] Memory leak detection tests cho sustained operations
  - [ ] UI responsiveness tests during heavy background processing

## Dev Notes

### Previous Story Context

From Story 3.2 completion notes:

- Configuration management system established với SQLite backend
- UI state management patterns available cho component updates
- Error handling system available cho configuration và persistence errors
- Real-time settings application functionality implemented

From Story 2.4 completion notes:

- Comprehensive error handling system với recovery mechanisms
- Progress dialog system available với cancellation support
- Background task execution patterns established
- Performance monitoring infrastructure foundations

### Performance Optimization Architecture

From backend architecture [Source: architecture/backend-architecture.md]:

**Enhanced Service Architecture for Performance**:

```python
class FileStreamingService:
    def __init__(self):
        self.chunk_size = 1000  # Configurable batch size
        self.cache = {}
        self.performance_metrics = PerformanceMetrics()
  
    async def scan_directory_chunked(
        self, 
        folder_path: str, 
        chunk_callback: Callable[[List[FileInfo]], None]
    ) -> AsyncGenerator[List[FileInfo], None]:
        """Stream directory contents in configurable chunks"""
      
    async def generate_preview_parallel(
        self,
        files: List[FileInfo],
        rules: NormalizationRules,
        max_workers: int = None
    ) -> AsyncGenerator[List[RenamePreview], None]:
        """Generate previews using parallel processing"""
```

**Async Repository Pattern for Large Operations**:

```python
class PerformantConfigRepository:
    async def bulk_save_operations(
        self,
        operations: List[OperationHistory]
    ) -> None:
        """Optimized batch database operations"""
        async with self.get_connection() as conn:
            cursor = conn.cursor()
            # Use executemany() for efficient bulk operations
            cursor.executemany("""
                INSERT INTO operation_history 
                (operation_id, timestamp, folder_path, file_mappings)
                VALUES (?, ?, ?, ?)
            """, [(op.operation_id, op.timestamp, op.folder_path, 
                   json.dumps(op.file_mappings)) for op in operations])
            conn.commit()
```

### Memory Management Architecture

From tech stack [Source: architecture/tech-stack.md]:

**Memory-Efficient Data Processing**:

| Component           | Optimization Strategy                      | Technology           |
| ------------------- | ------------------------------------------ | -------------------- |
| File Scanning       | Generator-based streaming                  | Python generators    |
| Preview Generation  | Chunked processing với parallel execution | concurrent.futures   |
| Database Operations | Bulk operations với prepared statements   | SQLite executemany   |
| UI Updates          | Virtualized list với lazy loading         | tkinter.ttk.Treeview |

**Memory Management Implementation Pattern**:

```python
from typing import Generator, Iterator
import gc
import psutil
from concurrent.futures import ThreadPoolExecutor, as_completed

class MemoryAwareFileProcessor:
    def __init__(self):
        self.memory_threshold = 0.8  # 80% của available RAM
        self.chunk_size = self._calculate_optimal_chunk_size()
      
    def _calculate_optimal_chunk_size(self) -> int:
        """Calculate optimal chunk size based on available memory"""
        available_memory = psutil.virtual_memory().available
        return min(max(100, available_memory // (1024 * 1024 * 10)), 5000)
  
    def process_files_chunked(
        self, 
        file_paths: Iterator[str],
        processor: Callable[[str], Any]
    ) -> Generator[Any, None, None]:
        """Process files in memory-efficient chunks"""
        chunk = []
        for file_path in file_paths:
            chunk.append(file_path)
          
            if len(chunk) >= self.chunk_size:
                yield from self._process_chunk(chunk, processor)
                chunk.clear()
                gc.collect()  # Force garbage collection
      
        if chunk:
            yield from self._process_chunk(chunk, processor)
```

### Asynchronous Processing Architecture

From frontend architecture [Source: architecture/frontend-architecture.md]:

**Enhanced State Management for Performance**:

```python
@dataclass
class PerformanceState:
    # Performance Metrics
    current_memory_usage: float = 0.0
    cpu_usage_percentage: float = 0.0
    files_processed_per_second: float = 0.0
  
    # Progress Tracking
    total_files_to_process: int = 0
    files_processed: int = 0
    estimated_completion_time: Optional[datetime] = None
  
    # Background Tasks
    active_background_tasks: List[str] = field(default_factory=list)
    task_queue_size: int = 0
  
    # File System Monitoring
    file_system_changes_detected: int = 0
    last_change_timestamp: Optional[datetime] = None

class AsyncStateManager:
    def __init__(self):
        self.state = ApplicationState()
        self.performance_state = PerformanceState()
        self.task_queue = asyncio.Queue()
        self.background_tasks: Set[asyncio.Task] = set()
  
    async def schedule_background_task(
        self,
        task_coro: Coroutine,
        priority: int = 0
    ) -> str:
        """Schedule background task với priority support"""
        task_id = str(uuid.uuid4())
        await self.task_queue.put((priority, task_id, task_coro))
        return task_id
  
    async def process_background_tasks(self) -> None:
        """Process background tasks without blocking UI"""
        while True:
            try:
                priority, task_id, coro = await asyncio.wait_for(
                    self.task_queue.get(), 
                    timeout=0.1
                )
                task = asyncio.create_task(coro)
                self.background_tasks.add(task)
                task.add_done_callback(self.background_tasks.discard)
              
            except asyncio.TimeoutError:
                # Allow UI updates
                await asyncio.sleep(0.001)
```

### File System Monitoring Integration

From components architecture [Source: architecture/components.md]:

**File System Watcher Implementation**:

```python
import asyncio
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
from typing import Callable, Optional
from threading import Timer

class PerformantFileSystemWatcher(FileSystemEventHandler):
    def __init__(self, callback: Callable[[str, str], None]):
        self.callback = callback
        self.debounce_timer: Optional[Timer] = None
        self.pending_changes: Set[str] = set()
        self.debounce_delay = 0.5  # 500ms debounce
  
    def on_modified(self, event):
        if not event.is_directory:
            self.pending_changes.add(event.src_path)
            self._schedule_callback()
  
    def on_created(self, event):
        if not event.is_directory:
            self.pending_changes.add(event.src_path)
            self._schedule_callback()
  
    def on_deleted(self, event):
        if not event.is_directory:
            self.pending_changes.add(event.src_path)
            self._schedule_callback()
  
    def _schedule_callback(self):
        """Debounced callback để avoid excessive notifications"""
        if self.debounce_timer:
            self.debounce_timer.cancel()
      
        self.debounce_timer = Timer(
            self.debounce_delay,
            self._execute_callback
        )
        self.debounce_timer.start()
  
    def _execute_callback(self):
        """Execute callback với collected changes"""
        if self.pending_changes:
            changes = list(self.pending_changes)
            self.pending_changes.clear()
            self.callback("file_changes", changes)
```

### UI Performance Optimization

From frontend architecture [Source: architecture/frontend-architecture.md]:

**Virtualized File List Component**:

```python
class PerformantFilePreview(BaseComponent):
    def __init__(self, parent, state_callback):
        super().__init__(parent, state_callback)
        self.visible_items = 100  # Only render visible items
        self.scroll_position = 0
        self.total_items = 0
        self.item_cache = {}
      
    def setup_ui(self):
        """Create virtualized treeview với performance optimizations"""
        self.tree = ttk.Treeview(
            self.parent,
            columns=('original', 'processed', 'status'),
            show='tree headings'
        )
      
        # Configure scrolling để update visible window
        self.tree.bind('<MouseWheel>', self._on_scroll)
        self.tree.bind('<Button-4>', self._on_scroll)
        self.tree.bind('<Button-5>', self._on_scroll)
      
    def update_data(self, file_previews: List[RenamePreview]):
        """Update data using virtualization"""
        self.total_items = len(file_previews)
      
        # Clear existing items
        for item in self.tree.get_children():
            self.tree.delete(item)
      
        # Render only visible items
        start_idx = self.scroll_position
        end_idx = min(start_idx + self.visible_items, self.total_items)
      
        for i in range(start_idx, end_idx):
            preview = file_previews[i]
            self.tree.insert('', 'end', values=(
                preview.original,
                preview.processed,
                preview.status
            ))
  
    def _on_scroll(self, event):
        """Handle scroll events cho virtualization"""
        # Update scroll position và re-render visible items
        delta = -1 * (event.delta // 120) if hasattr(event, 'delta') else (
            1 if event.num == 5 else -1
        )
      
        new_position = max(0, min(
            self.scroll_position + (delta * 10),
            self.total_items - self.visible_items
        ))
      
        if new_position != self.scroll_position:
            self.scroll_position = new_position
            self._refresh_visible_items()
```

### Performance Monitoring Integration

From unified project structure [Source: architecture/unified-project-structure.md]:

**Performance Monitor Component Locations**:

- Performance Monitor: `src/core/utils/performance_monitor.py`
- Streaming Service: `src/core/services/file_streaming_service.py`
- Async State Manager: `src/ui/async_state_manager.py`
- File System Watcher: `src/core/utils/file_system_watcher.py`

**Performance Monitoring Implementation**:

```python
import psutil
import time
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta

@dataclass
class PerformanceMetrics:
    memory_usage_mb: float
    cpu_percentage: float
    io_read_bytes: int
    io_write_bytes: int
    operation_duration_ms: float
    files_per_second: float
    timestamp: datetime

class PerformanceMonitor:
    def __init__(self):
        self.metrics_history: List[PerformanceMetrics] = []
        self.baseline_memory = psutil.virtual_memory().used
        self.operation_start_time: Optional[float] = None
      
    def start_operation_tracking(self):
        """Begin tracking performance metrics cho an operation"""
        self.operation_start_time = time.time()
      
    def record_metrics(self, files_processed: int = 0):
        """Record current performance metrics"""
        memory = psutil.virtual_memory()
        cpu_percent = psutil.cpu_percent()
        io_counters = psutil.disk_io_counters()
      
        duration_ms = 0
        files_per_second = 0
      
        if self.operation_start_time:
            duration_ms = (time.time() - self.operation_start_time) * 1000
            if duration_ms > 0 and files_processed > 0:
                files_per_second = files_processed / (duration_ms / 1000)
      
        metrics = PerformanceMetrics(
            memory_usage_mb=memory.used / (1024 * 1024),
            cpu_percentage=cpu_percent,
            io_read_bytes=io_counters.read_bytes if io_counters else 0,
            io_write_bytes=io_counters.write_bytes if io_counters else 0,
            operation_duration_ms=duration_ms,
            files_per_second=files_per_second,
            timestamp=datetime.now()
        )
      
        self.metrics_history.append(metrics)
        return metrics
  
    def get_performance_summary(self) -> Dict[str, float]:
        """Get performance summary cho the last operation"""
        if not self.metrics_history:
            return {}
      
        recent_metrics = self.metrics_history[-10:]  # Last 10 measurements
      
        return {
            'avg_memory_mb': sum(m.memory_usage_mb for m in recent_metrics) / len(recent_metrics),
            'max_cpu_percent': max(m.cpu_percentage for m in recent_metrics),
            'avg_files_per_second': sum(m.files_per_second for m in recent_metrics) / len(recent_metrics),
            'total_duration_ms': recent_metrics[-1].operation_duration_ms if recent_metrics else 0
        }
```

### Error Handling và Recovery

From error handling system [Source: Story 2.4 completion notes]:

**Performance-Related Error Scenarios**:

- Memory exhaustion during large operations
- File system monitoring failures
- Background task queue overflow
- UI thread blocking detection
- Performance threshold violations

**Enhanced Error Recovery Strategies**:

- Adaptive chunk size reduction for memory constraints
- Graceful background task cancellation
- UI responsiveness monitoring với automatic threading
- Performance-based operation throttling
- Emergency resource cleanup procedures

### Technology Stack Requirements

From tech stack [Source: architecture/tech-stack.md]:

| Component             | Technology                    | Purpose                      |
| --------------------- | ----------------------------- | ---------------------------- |
| Async Processing      | asyncio                       | Non-blocking operations      |
| File Monitoring       | watchdog                      | File system change detection |
| Memory Monitoring     | psutil                        | System resource tracking     |
| Parallel Processing   | concurrent.futures            | Multi-threaded operations    |
| Performance Profiling | cProfile                      | Bottleneck identification    |
| UI Virtualization     | tkinter.ttk với custom logic | Large list rendering         |

### Testing

#### Testing Standards

From testing strategy [Source: architecture/testing-strategy.md]:

**Unit Tests**:

- Location: `tests/unit/test_performance_optimization.py`
- Framework: pytest với performance benchmarks
- Coverage: File streaming service, memory management, async operations

**Performance Benchmarks**:

- Location: `tests/performance/test_large_file_handling.py`
- Framework: pytest-benchmark với memory profiling
- Coverage: Large directory scanning, memory usage tracking, UI responsiveness

**Integration Tests**:

- Location: `tests/integration/test_performance_integration.py`
- Framework: pytest với mock large datasets
- Coverage: End-to-end performance workflows, resource monitoring

#### Specific Testing Requirements for This Story:

- Test file streaming service với directories containing 1000, 10000, và 50000+ files
- Test memory usage stability during sustained operations
- Test UI responsiveness during heavy background processing
- Test file system monitoring với rapid file changes
- Test performance metrics collection và reporting accuracy
- Test adaptive performance scaling based on system capabilities
- Test background task cancellation và cleanup
- Test estimated completion time calculation accuracy
- Test virtualized UI components với large datasets
- Test error recovery for memory exhaustion scenarios

## Change Log

| Date       | Version | Description                                     | Author        |
| ---------- | ------- | ----------------------------------------------- | ------------- |
| 2025-09-01 | v1.0    | Initial story creation from Epic 3 requirements | Anh Minh (SM) |

## Dev Agent Record

*This section will be populated by the development agent during implementation*

## QA Results

*This section will be populated by the QA agent after story completion*
